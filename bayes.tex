\section{Bayes' Formula}

%
\begin{frame}
Remember our definition of conditional probability:

\begin{align*}
P(A \text{ and } B) &= P(A \mid B) P(B) \\
P(B \text{ and } A) &= P(B \mid A) P(A) \\
\end{align*}

Setting these equal to one another leads us to \textbf{Bayes' Formula}

$$ P(A \mid B) = \frac{ P(B \mid A) P(A) }{ P(B) } $$

\end{frame}
%

%
\begin{frame}

This is probably the most important simple foruma in both probability and
statistics

$$ P(A \mid B) = \frac{ P(B \mid A) P(A) }{ P(B) } $$

\end{frame}
%

%
\begin{frame}

Let's study a classic thought experiment: the disease screening problem.

Suppose we have developed a test for a certain desease:
\begin{itemize}
\item Only 1 \% of people have the disease.
\item If a person has the disease, the test will be positive 99.9 \% of the
time.
\item If a person does not ahve the disease, the test will be negative 98 \% of
the time.
\end{itemize}

You get tested for the desease, and the test is positive.  \textbf{What is the
probablility that you actually have the disease}?

\end{frame}
%

%
\begin{frame}
We are after the following conditional probability

$$ P(\text{Have Disease} \mid \text{Test is Positive)} $$

And we \textbf{know}

$$ P(\text{Have Disease}) = 0.01 $$
$$ P(\text{Test is Positive} \mid \text{Have Disease}) = 0.999 $$
$$ P(\text{Test is Positive} \mid \text{Do Not Have Disease}) = 0.02 $$
\end{frame}
%

%
\begin{frame}
Bayes theorem says:

\begin{align*}
P(\text{Have Disease}  & \mid \text{Test is Positive)} = \\
%
& = \frac{  P(\text{Test is
Positive} \mid \text{Have Disease}) P(\text{Have Disease}) } { P(\text{Test is
Positive}) }
\end{align*}

We know all the things appearing in this formula except $ P(\text{Test is
Positive}) $.

\end{frame}
%

%
\begin{frame}

We can caluculate the last piece by breaking things down

\begin{align*}
P(\text{Test} & \text{ is Positive}) \\
%
&= P(\text{Test is Positive and Have Disease}) \\
%
& \quad + P(\text{Test is Positive and Don't Have Disease}) \\
\end{align*}

\end{frame}
%

%
\begin{frame}

\begin{align*}
P(\text{Test} & \text{ is Positive and Have Disease}) \\
%
=& P(\text{Test is Positive} \mid \text{Have Disease}) P(\text{Have Disease}) \\
=& 0.999 \times 0.01 \\
\end{align*}

\end{frame}
%

%
\begin{frame}

\begin{align*}
P(\text{Test} & \text{ is Positive and Don't Have Disease}) \\
%
=& P(\text{Test is Positive} \mid \text{Don't Have Disease}) P(\text{Don't Have Disease}) \\
=& 0.02 \times 0.99 \\
\end{align*}

\end{frame}


\begin{frame}

We have all the pieces, so let's put them together

\begin{align*}
P(\text{Have Disease}  & \mid \text{Test is Positive)} = \\
%
&= \frac{  P(\text{Test is
Positive} \mid \text{Have Disease}) P(\text{Have Disease}) } { P(\text{Test is
Positive}) } \\
%
&= \frac{ 0.999 \times 0.01 } {  0.999 \times 0.01 +  0.02 \times 0.99 } \\
%
&= 0.34
\end{align*}

The probability we have the desease is called only 34 \%, \textbf{even after we
have recieved a positive test}.

\end{frame}
%

%
\begin{frame}

This kind of result is unituitive to almost all humans, a mental bias called the
\textbf{base rate fallacy}.

Pretty much \textbf{everyone's} intutition says that it should be much more
likely that the person does have the desease after a test comes back positive.
Pretty much \textbf{everyone} undervalues the prior information that

$$ P(\text{Have Disease}) = 0.01 $$

\textbf{I takes a lot of evidence to take an unlikely situation and make it
likely.}

\end{frame}
